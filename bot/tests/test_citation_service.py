"""
Tests for Citation Service

Comprehensive tests for citation formatting and context building functionality.
"""

from services.citation_service import CitationService


class TestCitationService:
    """Test citation service functionality"""

    def setup_method(self):
        """Set up test fixtures"""
        self.citation_service = CitationService()

    def test_add_source_citations_empty_chunks(self):
        """Test citation handling with empty context chunks"""
        response = "This is a test response."
        result = self.citation_service.add_source_citations(response, [])
        assert result == response

    def test_add_source_citations_single_chunk(self):
        """Test citation with single context chunk"""
        response = "Apple is a tech company."
        context_chunks = [
            {
                "content": "Apple content...",
                "similarity": 0.95,
                "metadata": {"file_name": "Apple - Project Details File.pdf"},
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "**ðŸ“š Sources:**" in result
        assert "1. Apple - Project Details File" in result
        assert "Match: 95.0%" in result
        assert "(:file_folder: Knowledge Base)" in result

    def test_add_source_citations_multiple_chunks_same_file(self):
        """Test citation with multiple chunks from same file"""
        response = "Apple information."
        context_chunks = [
            {
                "content": "Apple content 1...",
                "similarity": 0.95,
                "metadata": {"file_name": "Apple - Project Details File.pdf"},
            },
            {
                "content": "Apple content 2...",
                "similarity": 0.90,
                "metadata": {"file_name": "Apple - Project Details File.pdf"},
            },
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        # Should only have one citation but mention multiple sections
        assert result.count("1. Apple - Project Details File") == 1
        assert "2 sections" in result
        assert "Match: 95.0%" in result  # Should use highest similarity

    def test_add_source_citations_multiple_different_files(self):
        """Test citation with chunks from different files"""
        response = "Information about companies."
        context_chunks = [
            {
                "content": "Apple content...",
                "similarity": 0.95,
                "metadata": {"file_name": "Apple - Project Details File.pdf"},
            },
            {
                "content": "3Step content...",
                "similarity": 0.88,
                "metadata": {"file_name": "3Step - Scheduler Case Study.docx"},
            },
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "1. Apple - Project Details File" in result
        assert "2. 3Step - Scheduler Case Study" in result
        assert "Match: 95.0%" in result
        assert "Match: 88.0%" in result

    def test_add_source_citations_with_subtitle(self):
        """Test citation with subtitle in metadata"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content...",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Apple - Project Details File.pdf",
                    "title": "Advanced Project Management",
                },
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "1. Apple - Project Details File â€¢ Advanced Project Management" in result

    def test_add_source_citations_with_web_link(self):
        """Test citation with web view link"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content...",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Apple - Project Details File.pdf",
                    "web_view_link": "https://drive.google.com/file/d/123/view",
                },
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "[1. Apple - Project Details File" in result
        assert "](https://drive.google.com/file/d/123/view)" in result

    def test_add_source_citations_removes_file_extensions(self):
        """Test that file extensions are properly removed"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content 1...",
                "similarity": 0.90,
                "metadata": {"file_name": "Document.pdf"},
            },
            {
                "content": "Content 2...",
                "similarity": 0.85,
                "metadata": {"file_name": "Report.docx"},
            },
            {
                "content": "Content 3...",
                "similarity": 0.80,
                "metadata": {"file_name": "Notes.txt"},
            },
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "1. Document" in result
        assert "2. Report" in result
        assert "3. Notes" in result
        assert ".pdf" not in result
        assert ".docx" not in result
        assert ".txt" not in result

    def test_add_source_citations_deduplication(self):
        """Test that duplicate sources are properly deduplicated"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content 1...",
                "similarity": 0.95,
                "metadata": {"file_name": "Apple - Project Details File.pdf"},
            },
            {
                "content": "Content 2...",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Apple - PROJECT DETAILS File.PDF"
                },  # Different case
            },
            {
                "content": "Content 3...",
                "similarity": 0.85,
                "metadata": {"file_name": "Other Document.pdf"},
            },
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        # Should deduplicate similar file names (case insensitive)
        citations = result.split("**ðŸ“š Sources:**")[1]
        assert citations.count("Apple - Project Details File") == 1
        # Note: The deduplication means only 2 sources shown, not chunk count
        assert "1. Apple - Project Details File" in result
        assert "2. Other Document" in result

    def test_add_source_citations_unknown_filename(self):
        """Test citation with missing file name"""
        response = "Test response."
        context_chunks = [
            {"content": "Content...", "similarity": 0.90, "metadata": {}},
            {
                "content": "Content 2...",
                "similarity": 0.85,
                "metadata": {"file_name": ""},  # Empty file name
            },
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "1. Document 1" in result
        # Empty file name results in just the number, so check for that pattern
        sources_section = result.split("**ðŸ“š Sources:**")[1]
        assert "2." in sources_section

    def test_add_source_citations_zero_similarity(self):
        """Test citation with zero similarity score"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content...",
                "similarity": 0.0,
                "metadata": {"file_name": "Test Document.pdf"},
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "Match: 0.0%" in result

    def test_format_context_for_llm_empty_chunks(self):
        """Test LLM context formatting with empty chunks"""
        result = self.citation_service.format_context_for_llm([])
        assert result == ""

    def test_format_context_for_llm_single_chunk(self):
        """Test LLM context formatting with single chunk"""
        context_chunks = [
            {
                "content": "This is test content for the LLM.",
                "similarity": 0.95,
                "metadata": {"file_name": "Test Document.pdf"},
            }
        ]

        result = self.citation_service.format_context_for_llm(context_chunks)

        assert "[Source: Test Document.pdf, Score: 0.95]" in result
        assert "This is test content for the LLM." in result

    def test_format_context_for_llm_multiple_chunks(self):
        """Test LLM context formatting with multiple chunks"""
        context_chunks = [
            {
                "content": "First content chunk.",
                "similarity": 0.95,
                "metadata": {"file_name": "Document 1.pdf"},
            },
            {
                "content": "Second content chunk.",
                "similarity": 0.88,
                "metadata": {"file_name": "Document 2.pdf"},
            },
        ]

        result = self.citation_service.format_context_for_llm(context_chunks)

        assert "[Source: Document 1.pdf, Score: 0.95]" in result
        assert "First content chunk." in result
        assert "[Source: Document 2.pdf, Score: 0.88]" in result
        assert "Second content chunk." in result
        # Should be separated by double newlines
        assert result.count("\n\n") >= 1

    def test_format_context_for_llm_no_metadata(self):
        """Test LLM context formatting without metadata"""
        context_chunks = [{"content": "Content without metadata.", "similarity": 0.80}]

        result = self.citation_service.format_context_for_llm(context_chunks)

        assert "[Score: 0.80]" in result
        assert "Content without metadata." in result
        assert "Source:" not in result

    def test_format_context_for_llm_missing_similarity(self):
        """Test LLM context formatting without similarity score"""
        context_chunks = [
            {
                "content": "Content without similarity.",
                "metadata": {"file_name": "Test Document.pdf"},
            }
        ]

        result = self.citation_service.format_context_for_llm(context_chunks)

        assert "[Source: Test Document.pdf, Score: 0.00]" in result
        assert "Content without similarity." in result

    def test_format_context_for_llm_empty_metadata(self):
        """Test LLM context formatting with empty metadata dict"""
        context_chunks = [
            {
                "content": "Content with empty metadata.",
                "similarity": 0.75,
                "metadata": {},
            }
        ]

        result = self.citation_service.format_context_for_llm(context_chunks)

        # Empty metadata is treated as no metadata, so just score
        assert "[Score: 0.75]" in result
        assert "Content with empty metadata." in result

    def test_citation_service_integration(self):
        """Test full integration of citation service methods"""
        # Simulate a complete RAG pipeline
        context_chunks = [
            {
                "content": "Apple Inc. is a multinational technology company.",
                "similarity": 0.95,
                "metadata": {
                    "file_name": "Apple - Company Overview.pdf",
                    "title": "Corporate Information",
                    "web_view_link": "https://drive.google.com/file/d/apple123/view",
                },
            },
            {
                "content": "Additional details about Apple's projects.",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Apple - Company Overview.pdf",
                    "title": "Corporate Information",
                },
            },
            {
                "content": "3Step provides tournament scheduling software.",
                "similarity": 0.85,
                "metadata": {"file_name": "3Step - Product Overview.docx"},
            },
        ]

        # Format for LLM
        llm_context = self.citation_service.format_context_for_llm(context_chunks)
        assert "Apple Inc. is a multinational technology company." in llm_context
        assert "3Step provides tournament scheduling software." in llm_context

        # Add citations to response
        response = "Both Apple and 3Step are technology companies with different specializations."
        cited_response = self.citation_service.add_source_citations(
            response, context_chunks
        )

        assert "**ðŸ“š Sources:**" in cited_response
        # The citation format puts sections before the subtitle
        assert "Apple - Company Overview" in cited_response
        assert "2 sections" in cited_response  # Multiple chunks from Apple doc
        assert "Corporate Information" in cited_response
        assert "2. 3Step - Product Overview" in cited_response
        assert "Match: 95.0%" in cited_response
        assert "Match: 85.0%" in cited_response
        assert "[1. Apple" in cited_response  # Should have web link
        assert "](https://drive.google.com/file/d/apple123/view)" in cited_response


class TestCitationServiceEdgeCases:
    """Test edge cases and error conditions"""

    def setup_method(self):
        """Set up test fixtures"""
        self.citation_service = CitationService()

    def test_malformed_context_chunks(self):
        """Test handling of malformed context chunks"""
        response = "Test response."
        malformed_chunks = [
            {},  # Empty chunk
            {"content": "Valid content"},  # Missing similarity and metadata
            {"similarity": 0.95},  # Missing content
            None,  # None value - this might cause issues
        ]

        # Filter out None values as they would likely cause errors
        safe_chunks = [chunk for chunk in malformed_chunks if chunk is not None]

        result = self.citation_service.add_source_citations(response, safe_chunks)

        # Should handle gracefully
        assert "Test response." in result

    def test_very_long_file_names(self):
        """Test handling of very long file names"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content...",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Very Long Document Name That Exceeds Normal Length Expectations And Contains Many Words That Might Cause Formatting Issues In Citations.pdf"
                },
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        # Should still work but truncate file extension
        assert (
            "Very Long Document Name That Exceeds Normal Length Expectations And Contains Many Words That Might Cause Formatting Issues In Citations"
            in result
        )
        assert ".pdf" not in result

    def test_special_characters_in_file_names(self):
        """Test handling of special characters in file names"""
        response = "Test response."
        context_chunks = [
            {
                "content": "Content...",
                "similarity": 0.90,
                "metadata": {
                    "file_name": "Document with (special) [chars] & symbols!.pdf"
                },
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        # Should preserve special characters but remove extension
        assert "Document with (special) [chars] & symbols!" in result
        assert ".pdf" not in result

    def test_unicode_characters_in_content(self):
        """Test handling of Unicode characters"""
        response = "Test response with Ã©mojis ðŸš€."
        context_chunks = [
            {
                "content": "Content with Ã©mojis ðŸŽ‰ and Ã¼nÃ¯cÃ¶dÃ© characters.",
                "similarity": 0.90,
                "metadata": {"file_name": "ÃœnÃ¯cÃ¶dÃ© Document.pdf"},
            }
        ]

        result = self.citation_service.add_source_citations(response, context_chunks)

        assert "ÃœnÃ¯cÃ¶dÃ© Document" in result
        assert "ðŸš€" in result

        # Test LLM formatting too
        llm_context = self.citation_service.format_context_for_llm(context_chunks)
        assert "Content with Ã©mojis ðŸŽ‰ and Ã¼nÃ¯cÃ¶dÃ© characters." in llm_context
