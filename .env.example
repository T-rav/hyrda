# Slack Configuration
SLACK_BOT_TOKEN=xoxb-your-bot-token-here
SLACK_APP_TOKEN=xapp-your-app-token-here

# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: openai, anthropic, ollama
LLM_API_KEY=your-openai-api-key-here
LLM_MODEL=gpt-4o-mini  # Or gpt-4, claude-3-haiku-20240307, etc.
LLM_BASE_URL=  # Optional: for ollama (http://localhost:11434) or custom endpoints
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# Vector Database Configuration (for RAG)
VECTOR_ENABLED=true
VECTOR_PROVIDER=chroma  # Options: chroma, pinecone
VECTOR_URL=http://localhost:8000  # ChromaDB server or local path
VECTOR_API_KEY=  # Required for Pinecone
VECTOR_COLLECTION_NAME=knowledge_base

# Embedding Configuration
EMBEDDING_PROVIDER=openai  # Options: openai, sentence-transformers
EMBEDDING_MODEL=text-embedding-3-small  # Or all-MiniLM-L6-v2 for sentence-transformers
EMBEDDING_API_KEY=  # Optional: uses LLM_API_KEY if not set
EMBEDDING_CHUNK_SIZE=1000
EMBEDDING_CHUNK_OVERLAP=200

# RAG Configuration
RAG_MAX_CHUNKS=5
RAG_SIMILARITY_THRESHOLD=0.7
RAG_RERANK_ENABLED=false
RAG_INCLUDE_METADATA=true

# Database Configuration (for user prompts)
DATABASE_ENABLED=true
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/slack_bot

# Cache Configuration (Redis)
CACHE_ENABLED=true
CACHE_REDIS_URL=redis://localhost:6379
CACHE_CONVERSATION_TTL=1800

# Agent Processes
AGENT_ENABLED=true

# Logging
LOG_LEVEL=INFO
DEBUG=false

# Health Check
HEALTH_PORT=8080

# Example configurations for different setups:

# === OpenAI + ChromaDB (Local) ===
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-your-openai-key
# LLM_MODEL=gpt-4o-mini
# VECTOR_PROVIDER=chroma
# VECTOR_URL=./chroma_db  # Local persistent storage
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small

# === Anthropic + Pinecone (Cloud) ===
# LLM_PROVIDER=anthropic
# LLM_API_KEY=your-anthropic-key
# LLM_MODEL=claude-3-haiku-20240307
# VECTOR_PROVIDER=pinecone
# VECTOR_URL=https://your-index-hash.svc.gcp-starter.pinecone.io
# VECTOR_API_KEY=your-pinecone-key
# EMBEDDING_PROVIDER=openai
# EMBEDDING_API_KEY=your-openai-key-for-embeddings

# === Ollama (Local) + ChromaDB ===
# LLM_PROVIDER=ollama
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama2  # or any model you have pulled
# VECTOR_PROVIDER=chroma
# VECTOR_URL=./chroma_db
# EMBEDDING_PROVIDER=sentence-transformers
# EMBEDDING_MODEL=all-MiniLM-L6-v2

# === Disable RAG (Traditional Mode) ===
# VECTOR_ENABLED=false
# # All other VECTOR_, EMBEDDING_, RAG_ settings will be ignored