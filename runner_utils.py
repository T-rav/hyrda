"""Shared subprocess streaming utilities for Claude agent runners."""

from __future__ import annotations

import asyncio
import contextlib
import logging
import os
import signal
from collections.abc import Callable
from pathlib import Path
from typing import Any

from events import EventBus, EventType, HydraEvent
from stream_parser import StreamParser
from subprocess_util import (
    CreditExhaustedError,
    is_credit_exhaustion,
    make_clean_env,
    parse_credit_resume_time,
)


async def stream_claude_process(
    *,
    cmd: list[str],
    prompt: str,
    cwd: Path,
    active_procs: set[asyncio.subprocess.Process],
    event_bus: EventBus,
    event_data: dict[str, Any],
    logger: logging.Logger,
    on_output: Callable[[str], bool] | None = None,
    timeout: float | None = None,
) -> str:
    """Run a ``claude -p`` subprocess and stream its output.

    Parameters
    ----------
    cmd:
        Command to execute (e.g. ``["claude", "-p", ...]``).
    prompt:
        Text to write to the process's stdin.
    cwd:
        Working directory for the subprocess.
    active_procs:
        Shared set for tracking active processes (for terminate).
    event_bus:
        For publishing ``TRANSCRIPT_LINE`` events.
    event_data:
        Base dict for event data (runner-specific keys like ``issue``/``pr``/``source``).
        ``"line"`` is added automatically per output line.
    logger:
        Caller's logger for warnings (preserves per-runner log context).
    on_output:
        Optional callback receiving accumulated display text.
        Return ``True`` to kill the process early.

    Returns
    -------
    str
        The transcript string, using the fallback chain:
        result_text → accumulated_text → raw_lines.
    """
    env = make_clean_env()

    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdin=asyncio.subprocess.PIPE,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        cwd=str(cwd),
        env=env,
        limit=1024 * 1024,  # 1 MB — stream-json lines can exceed 64 KB default
        start_new_session=True,  # Own process group for reliable cleanup
    )
    active_procs.add(proc)

    try:
        assert proc.stdin is not None
        assert proc.stdout is not None
        assert proc.stderr is not None

        stdout_stream = proc.stdout  # capture for nested function

        proc.stdin.write(prompt.encode())
        await proc.stdin.drain()
        proc.stdin.close()

        # Drain stderr in background to prevent deadlock
        stderr_task = asyncio.create_task(proc.stderr.read())

        parser = StreamParser()
        raw_lines: list[str] = []
        result_text = ""
        accumulated_text = ""
        early_killed = False

        async def _stream_body() -> str:
            nonlocal result_text, accumulated_text, early_killed

            async for raw in stdout_stream:
                line = raw.decode(errors="replace").rstrip("\n")
                raw_lines.append(line)
                if not line.strip():
                    continue

                display, result = parser.parse(line)
                if result is not None:
                    result_text = result

                if display.strip():
                    accumulated_text += display + "\n"
                    await event_bus.publish(
                        HydraEvent(
                            type=EventType.TRANSCRIPT_LINE,
                            data={**event_data, "line": display},
                        )
                    )

                if (
                    on_output is not None
                    and not early_killed
                    and on_output(accumulated_text)
                ):
                    early_killed = True
                    proc.kill()
                    break

            stderr_bytes = await stderr_task
            await proc.wait()

            stderr_text = stderr_bytes.decode(errors="replace").strip()

            if not early_killed and proc.returncode != 0:
                logger.warning(
                    "Process exited with code %d: %s",
                    proc.returncode,
                    stderr_text[:500],
                )

            # Check for credit exhaustion in both stderr and transcript.
            # Skip when early_killed=True — the process was intentionally killed by us
            # because it produced its expected output; credit phrases in legitimate
            # transcript content would otherwise cause false-positive pauses.
            combined = f"{stderr_text}\n{accumulated_text}"
            if not early_killed and is_credit_exhaustion(combined):
                resume_at = parse_credit_resume_time(combined)
                raise CreditExhaustedError("API credit limit reached", resume_at=resume_at)

            return result_text or accumulated_text.rstrip("\n") or "\n".join(raw_lines)

        if timeout is not None:
            return await asyncio.wait_for(_stream_body(), timeout=timeout)
        return await _stream_body()
    except TimeoutError:
        proc.kill()
        await proc.wait()
        raise RuntimeError(f"Claude process timed out after {timeout}s") from None
    except asyncio.CancelledError:
        proc.kill()
        raise
    finally:
        active_procs.discard(proc)


def terminate_processes(active_procs: set[asyncio.subprocess.Process]) -> None:
    """Kill all processes in *active_procs* and their process groups."""
    for proc in list(active_procs):
        with contextlib.suppress(ProcessLookupError, OSError):
            if proc.pid is not None:
                os.killpg(proc.pid, signal.SIGKILL)
            else:
                proc.kill()
